import os, argparse, datetime, torch, pandas as pd
from pathlib import Path
from tqdm import tqdm
from safetensors.torch import load_file
from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig
from peft import PeftModel
from smolvlm2_video_FT_lora import SmolVLMWithClassifier, get_latest_checkpoint

os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

def parse_args():
    parser = argparse.ArgumentParser("Dataset inference script (QLoRA, A/B)")
    parser.add_argument("--dataset", required=True, help="freeway / road / â€¦")
    parser.add_argument("--epoch", default=3, help="tag used in filename")
    parser.add_argument("--model-path", required=True, help="root where checkpoints/final live")
    parser.add_argument("--smol", action="store_true", help="True â†’ 500M, False â†’ 2.2B")
    parser.add_argument("--scheme", choices=["auto", "adapter", "merged"], default="auto",
                        help="adapter=æ–¹æ¡ˆA, merged=æ–¹æ¡ˆB, auto=è‡ªå‹•åµæ¸¬")
    parser.add_argument("--processor-dir", default="", help="å¯é¸ï¼›æŒ‡å®š tokenizer/processor ç›®éŒ„")
    return parser.parse_args()

args = parse_args()
root = Path(args.model_path)

# ---------------------- æŽ¢æ¸¬æª”æ¡ˆçµæ§‹ ----------------------
def find_final_dir(base: Path) -> Path | None:
    cand = [base / "final", base]
    for c in cand:
        if (c / "adapter" / "adapter_model.safetensors").exists() or (c / "model.safetensors").exists():
            return c
    return None

def find_checkpoint_dir(base: Path) -> Path | None:
    cands = []
    if args.processor_dir:
        cands.append(Path(args.processor_dir))
    try:
        latest = Path(get_latest_checkpoint(str(base)))
        cands.append(latest)
    except Exception:
        pass
    cands += [base / "checkpoint-36", base]
    for c in cands:
        if not c.exists(): continue
        has_tok = (c / "tokenizer.json").exists()
        has_added = (c / "added_tokens.json").exists()
        has_chat = (c / "chat_template.jinja").exists()
        if has_tok and (has_added or has_chat):
            return c
    for c in cands:
        if (c / "tokenizer.json").exists():
            return c
    return None

final_dir = find_final_dir(root)
proc_dir  = find_checkpoint_dir(root)
if final_dir is None:
    raise FileNotFoundError("æ‰¾ä¸åˆ° final/ æˆ– model æª”æ¡ˆæ‰€åœ¨çš„ç›®éŒ„ï¼Œè«‹ç¢ºèª --model-pathã€‚")
if proc_dir is None:
    raise FileNotFoundError("æ‰¾ä¸åˆ° tokenizer/processor çš„ç›®éŒ„ï¼Œè«‹åŠ ä¸Š --processor-dirã€‚")

adapter_dir   = final_dir / "adapter"
adapter_path  = adapter_dir / "adapter_model.safetensors"
clf_path      = final_dir / "classifier.safetensors"
merged_path   = final_dir / "model.safetensors"

# ---------------------- æ±ºå®šæ–¹æ¡ˆ -------------------------
scheme = args.scheme
if scheme == "auto":
    if adapter_path.exists() and clf_path.exists():
        scheme = "adapter"
    elif merged_path.exists():
        scheme = "merged"
    else:
        raise FileNotFoundError("auto æ¨¡å¼æ‰¾ä¸åˆ°å¯ç”¨çš„æª”æ¡ˆï¼šç¼º adapter+classifier æˆ– merged modelã€‚")
print(f"[info] ä½¿ç”¨æ–¹æ¡ˆï¼š{scheme.upper()}  |  final_dir={final_dir}  |  processor_dir={proc_dir}")
if scheme not in ("adapter", "merged"):
    raise ValueError(f"Unexpected scheme value: {scheme}")

# ---------------------- å½±ç‰‡èˆ‡è¼¸å‡º -----------------------
video_dir = Path(fr"C:\Python_workspace\TAISC\dataset\{args.dataset}_video\smolvlm2\test")
out_csv   = Path(".") / "program_test" / (
    f"infer_{scheme}_{args.dataset}_{args.epoch}epoch_{datetime.datetime.now():%H-%M-%S}.csv"
)
prompt = "Is a vehicle collision likely to happen within 1 to 2 seconds? (0: No, 1: Yes)"

# ---------------------- å»ºç«‹æ¨¡åž‹éª¨æž¶ ----------------------
model_id = ("HuggingFaceTB/SmolVLM2-500M-Video-Instruct"
            if args.smol else
            "HuggingFaceTB/SmolVLM2-2.2B-Instruct")

if scheme == "adapter":
    # === æ–¹æ¡ˆAï¼šæ­£è¦åšæ³•ï¼šç”¨ from_pretrained å»ºå‡º PeftModelï¼Œç„¶å¾Œå¡žå›žåŽ» ===
    # 1) å…ˆå»ºä½ çš„å¤–å±¤ï¼ˆç‚ºäº† classifier èˆ‡ forwardï¼‰ï¼Œä½†æœƒå…ˆå¸¶ä¸€å€‹æš«æ™‚çš„ base
    model = SmolVLMWithClassifier(model_id=model_id, USE_QLORA=True, infer=True).to(device).eval()

    # 2) ç”¨ 4-bit é…ç½®é‡æ–°å»ºã€Œä¹¾æ·¨çš„ baseã€
    bnb_cfg = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_use_double_quant=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16,
    )
    clean_base = AutoModelForImageTextToText.from_pretrained(
        model_id, quantization_config=bnb_cfg, device_map="auto"
    )

    # 3) ç”¨ PEFT å®˜æ–¹ API æŠŠ adapter å¥—åˆ°ä¹¾æ·¨çš„ base
    if not adapter_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° {adapter_path}")
    peft_model = PeftModel.from_pretrained(clean_base, str(adapter_dir), is_trainable=False)

    # 4) ç”¨æ–°çš„ peft_model å–ä»£å¤–å±¤è£¡çš„ base_modelï¼ˆä¸¦é‡‹æ”¾èˆŠçš„ï¼‰
    old = model.base_model
    model.base_model = peft_model
    del old, clean_base
    torch.cuda.empty_cache()

    # 5) è¼‰å…¥åˆ†é¡žé ­
    if clf_path.exists():
        state_clf = load_file(str(clf_path))
        miss_c, unexp_c = model.load_state_dict(state_clf, strict=False)
        print(f"[classifier] loaded âœ“  missing={len(miss_c)}  unexpected={len(unexp_c)}")
    else:
        print("[warn] æ‰¾ä¸åˆ° classifier.safetensorsï¼Œå°‡ä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–çš„åˆ†é¡žé ­ï¼ˆçµæžœå¯èƒ½ä¸æº–ï¼‰")

    # 6) å°æª¢æŸ¥ï¼šæ‡‰è©²æ˜¯ PeftModelã€è€Œä¸”å…·å‚™ adapter
    print("[debug] base type:", type(model.base_model))
    try:
        adapters = list(getattr(model.base_model, "peft_config", {}).keys())
        print("[debug] adapters:", adapters)
    except Exception:
        pass

elif scheme == "merged":
    # === æ–¹æ¡ˆBï¼šåˆä½µå¾Œæ•´é¡† ===
    model = SmolVLMWithClassifier(model_id=model_id, USE_QLORA=False, infer=True).to(device).eval()
    if not merged_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° {merged_path}")
    state_full = load_file(str(merged_path))
    miss_f, unexp_f = model.load_state_dict(state_full, strict=False)
    print(f"[merged] loaded âœ“  missing={len(miss_f)}  unexpected={len(unexp_f)}")

# ---------------------- Processor ------------------------
processor = AutoProcessor.from_pretrained(str(proc_dir))

# ---------------------- å½±ç‰‡æ¸…å–® -------------------------
vid_files = [f for f in os.listdir(video_dir) if f.endswith(".mp4")]
vid_paths = [video_dir / f for f in vid_files]
if not vid_paths:
    raise FileNotFoundError(f"åœ¨ {video_dir} æ‰¾ä¸åˆ° mp4 å½±ç‰‡ã€‚")

# ---------------------- æŽ¨è«–è¿´åœˆ ------------------------
results = []
for path, name in tqdm(list(zip(vid_paths, vid_files)), desc="infer"):
    messages = [{"role": "user",
                 "content": [{"type": "text",  "text": prompt},
                             {"type": "video", "path": str(path)}]}]

    inputs = processor.apply_chat_template(
        messages, tokenize=True, add_generation_prompt=False,
        return_tensors="pt", return_dict=True
    )

    proc_in = {}
    for k, v in inputs.items():
        if not isinstance(v, torch.Tensor):
            continue
        if k == "pixel_values":
            # é¿å…ä¸å¿…è¦ castï¼›è‹¥ base æœ‰ dtype å†å°é½Š
            target = getattr(model.base_model, "dtype", None)
            proc_in[k] = v.to(device, dtype=target) if target is not None else v.to(device)
        elif k in ("input_ids", "attention_mask"):
            proc_in[k] = v.to(device, dtype=torch.long)
        else:
            proc_in[k] = v.to(device)

    with torch.inference_mode():
        logit = model(**proc_in).to(torch.float32).squeeze(-1)
        prob  = torch.sigmoid(logit).item()
        pred  = int(prob > 0.5)

    tqdm.write(f"[âœ“] {name} â†’ p={prob:.5f} â‡’ {pred}")
    results.append({"file_name": name, "risk": pred})

# ---------------------- å­˜æª” -----------------------------
out_csv = Path(".") / "program_test" / (
    f"infer_{scheme}_{args.dataset}_{args.epoch}epoch_{datetime.datetime.now():%H-%M-%S}.csv"
)
out_csv.parent.mkdir(parents=True, exist_ok=True)
pd.DataFrame(results).to_csv(out_csv, index=False)
print(f"\nðŸ“„ Results saved to: {out_csv}")