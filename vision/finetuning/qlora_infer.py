# """
# æŽ¨è«–æµç¨‹ï¼š
# 1. é€éŽ get_latest_checkpoint() æ‰¾åˆ°åŒ…å«
#      - model.safetensors        (4-bit åŸºåº•)
#      - adapter_model.safetensors(LoRA + classifier)
#    çš„è³‡æ–™å¤¾
# 2. å»º SmolVLMWithClassifier(USE_QLORA=True)  â‡’ å·²è‡ªå‹•æŠŠ 4-bit åŸºåº•è¼‰å¥½
# 3. åªæŠŠ adapter_model.safetensors æ¬Šé‡è¦†è“‹é€²åŽ»
# 4. å½±ç‰‡è®€å– & Processor èˆ‡èˆŠç‰ˆ custom_infer.py å®Œå…¨ä¸€è‡´
# """

# import os, argparse, datetime, torch, pandas as pd
# from tqdm import tqdm
# from safetensors.torch import load_file
# from transformers import AutoProcessor
# from smolvlm2_video_FT_lora import SmolVLMWithClassifier, get_latest_checkpoint

# os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
# device = "cuda" if torch.cuda.is_available() else "cpu"

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI åƒæ•¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def parse_args():
#     parser = argparse.ArgumentParser("Dataset inference script (QLoRA)")
#     parser.add_argument("--dataset", required=True, help="freeway / road / â€¦")
#     parser.add_argument("--epoch", default=3, help="tag used in folder name")
#     parser.add_argument("--model-path", required=True, help="root where checkpoints live")
#     # parser.add_argument("--qlora", action="store_true", help="set True if the checkpointä½¿ç”¨QLoRA(é è¨­ False)")
#     parser.add_argument("--smol", action="store_true", help="True â†’ 500 M, False â†’ 2.2 B")
#     parser.add_argument("--scheme", choices=["auto", "adapter", "merged"], default="auto",
#                     help="adapter=æ–¹æ¡ˆA, merged=æ–¹æ¡ˆB, auto=è‡ªå‹•åµæ¸¬")
#     parser.add_argument("--processor-dir", default="", help="å¯é¸ï¼›æŒ‡å®š tokenizer/processor ç›®éŒ„")

#     return parser.parse_args()

# args = parse_args()

# ckpt_dir = get_latest_checkpoint(args.model_path)
# video_dir = fr"C:\Python_workspace\TAISC\dataset\{args.dataset}_video\smolvlm2\test"
# out_csv = ".\\program_test\\qlora_{}_{}epoch_infer_results_{}.csv".format(args.dataset , args.epoch , str(datetime.datetime.now())[11:19].replace(":" , "-"))
# # out_csv = (f".\\program_test\\full_{args.dataset}_{args.epoch}epoch_"
# #                f"infer_{datetime.datetime.now():%H-%M-%S}.csv")
# prompt = "Is a vehicle collision likely to happen within 1 to 2 seconds?(0: No, 1: Yes)"

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å»ºç«‹æ¨¡åž‹éª¨æž¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# model_id = "HuggingFaceTB/SmolVLM2-500M-Video-Instruct" if args.smol else "HuggingFaceTB/SmolVLM2-2.2B-Instruct"

# model = SmolVLMWithClassifier(
#     model_id=model_id,
#     USE_QLORA=args.qlora,     # True â†’ å»º LoRA adapter çµæ§‹
#     infer=True
# ).to(device).eval()

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åªè¼‰ LoRA + classifier æ¬Šé‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€
# if args.qlora:
#     adapter_path = os.path.join(ckpt_dir, "adapter_model.safetensors")
#     state = load_file(adapter_path)
#     miss, unexp = model.load_state_dict(state, strict=False)
#     print(f"[LoRA] loaded  âœ“  missing={len(miss)}  unexpected={len(unexp)}")
# else:                           # å…¨é‡å¾®èª¿æ™‚æ‰è®€ model.safetensors
#     full_path = os.path.join(ckpt_dir, "model.safetensors")
#     state = load_file(full_path)
#     model.load_state_dict(state)
#     print("[full] model.safetensors loaded")

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Processor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# processor = AutoProcessor.from_pretrained(ckpt_dir)

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å½±ç‰‡æ¸…å–® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# vid_files = [f for f in os.listdir(video_dir) if f.endswith(".mp4")]
# vid_paths = [os.path.join(video_dir, f) for f in vid_files]

# results = []
# for path, name in tqdm(list(zip(vid_paths, vid_files)), desc="infer"):
#     messages = [{"role": "user",
#                  "content": [{"type": "text",  "text": prompt},
#                              {"type": "video", "path": path}]}]

#     inputs = processor.apply_chat_template(
#         messages, tokenize=True, add_generation_prompt=False,
#         return_tensors="pt", return_dict=True
#     )

#     proc_in = {}
#     for k, v in inputs.items():
#         if not isinstance(v, torch.Tensor):  # ä¸æ˜¯ tensor ç›´æŽ¥è·³éŽ
#             continue
#         if k == "pixel_values":
#             proc_in[k] = v.to(device, dtype=model.base_model.dtype)
#         elif k in ["input_ids", "attention_mask"]:
#             proc_in[k] = v.to(device, dtype=torch.long)
#         else:
#             proc_in[k] = v.to(device)

#     with torch.inference_mode():
#         logit = model(**proc_in).squeeze(-1)
#         p     = torch.sigmoid(logit).item()
#         pred  = int(p > 0.5)

#     tqdm.write(f"[âœ“] {name} â†’ p={p:.3f} â‡’ {pred}")
#     results.append({"file_name": name, "risk": pred})

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å­˜çµæžœ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# pd.DataFrame(results).to_csv(out_csv, index=False)
# print(f"\nðŸ“„ All results saved to: {out_csv}")


"""
æ”¯æ´å…©ç¨®æŽ¨è«–æ–¹æ¡ˆï¼š
A. åˆ†é›¢ (adapter + classifier)   â†’ ä»¥ final/adapter + final/classifier.safetensors ç‚ºä¸»
B. åˆä½µ (merged single model)     â†’ ä»¥ final/model.safetensors ç‚ºä¸»

åŒæ™‚è‡ªå‹•æŒ‘é¸ tokenizer/processorï¼šå„ªå…ˆä½¿ç”¨åŒ…å« added_tokens.jsonã€chat_template.jinja çš„è³‡æ–™å¤¾
ï¼ˆé€šå¸¸æ˜¯ checkpoint-XX/ï¼‰ï¼Œä¹Ÿå¯ç”¨ --processor-dir è¦†å¯«ã€‚
"""

import os, argparse, datetime, torch, pandas as pd
from pathlib import Path
from tqdm import tqdm
from safetensors.torch import load_file
from transformers import AutoProcessor
from smolvlm2_video_FT_lora import SmolVLMWithClassifier, get_latest_checkpoint

os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
device = "cuda" if torch.cuda.is_available() else "cpu"

def parse_args():
    parser = argparse.ArgumentParser("Dataset inference script (QLoRA, A/B)")
    parser.add_argument("--dataset", required=True, help="freeway / road / â€¦")
    parser.add_argument("--epoch", default=3, help="tag used in filename")
    parser.add_argument("--model-path", required=True, help="root where checkpoints/final live")
    parser.add_argument("--smol", action="store_true", help="True â†’ 500M, False â†’ 2.2B")
    parser.add_argument("--scheme", choices=["auto", "adapter", "merged"], default="auto",
                    help="adapter=æ–¹æ¡ˆA, merged=æ–¹æ¡ˆB, auto=è‡ªå‹•åµæ¸¬")
    parser.add_argument("--processor-dir", default="", help="å¯é¸ï¼›æŒ‡å®š tokenizer/processor ç›®éŒ„")
    return parser.parse_args()

args = parse_args()
root = Path(args.model_path)

# ---------------------- æŽ¢æ¸¬æª”æ¡ˆçµæ§‹ ----------------------
def find_final_dir(base: Path) -> Path | None:
    cand = [base / "final", base]
    for c in cand:
        if (c / "adapter" / "adapter_model.safetensors").exists() or (c / "model.safetensors").exists():
            return c
    return None

def find_checkpoint_dir(base: Path) -> Path | None:
    # å„ªå…ˆï¼šä½¿ç”¨å¸¶æœ‰ tokenizer èˆ‡ chat_template çš„è³‡æ–™å¤¾
    cands = []
    if args.processor_dir:
        cands.append(Path(args.processor_dir))
    # æœ€æ–° checkpoint
    try:
        latest = Path(get_latest_checkpoint(str(base)))
        cands.append(latest)
    except Exception:
        pass
    # å¸¸è¦‹ä½ç½®
    cands += [base / "checkpoint-36", base]
    # éŽæ¿¾å‡ºå« tokenizer.json çš„ç›®éŒ„
    for c in cands:
        if not c.exists():
            continue
        has_tok = (c / "tokenizer.json").exists()
        has_added = (c / "added_tokens.json").exists()
        has_chat = (c / "chat_template.jinja").exists()
        if has_tok and (has_added or has_chat):
            return c
    # å¾Œå‚™ï¼šä»»ä½•å« tokenizer.json çš„ç›®éŒ„
    for c in cands:
        if (c / "tokenizer.json").exists():
            return c
    return None

final_dir = find_final_dir(root)
proc_dir  = find_checkpoint_dir(root)
if final_dir is None:
    raise FileNotFoundError("æ‰¾ä¸åˆ° final/ æˆ– model æª”æ¡ˆæ‰€åœ¨çš„ç›®éŒ„ï¼Œè«‹ç¢ºèª --model-pathã€‚")
if proc_dir is None:
    raise FileNotFoundError("æ‰¾ä¸åˆ° tokenizer/processor çš„ç›®éŒ„ï¼Œè«‹åŠ ä¸Š --processor-dirã€‚")

adapter_dir   = final_dir / "adapter"
adapter_path  = adapter_dir / "adapter_model.safetensors"
clf_path      = final_dir / "classifier.safetensors"
merged_path   = final_dir / "model.safetensors"

# ---------------------- æ±ºå®šæ–¹æ¡ˆ -------------------------
scheme = args.scheme
if scheme == "auto":
    if adapter_path.exists() and clf_path.exists():
        scheme = "adapter"
    elif merged_path.exists():
        scheme = "merged"
    else:
        raise FileNotFoundError("auto æ¨¡å¼æ‰¾ä¸åˆ°å¯ç”¨çš„æª”æ¡ˆï¼šç¼º adapter+classifier æˆ– merged modelã€‚")
print(f"[info] ä½¿ç”¨æ–¹æ¡ˆï¼š{scheme.upper()}  |  final_dir={final_dir}  |  processor_dir={proc_dir}")

# ---------------------- å½±ç‰‡èˆ‡è¼¸å‡º -----------------------
video_dir = Path(fr"C:\Python_workspace\TAISC\dataset\{args.dataset}_video\smolvlm2\test")
out_csv   = Path(".") / "program_test" / (
    f"infer_{scheme}_{args.dataset}_{args.epoch}epoch_{datetime.datetime.now():%H-%M-%S}.csv"
)

prompt = "Is a vehicle collision likely to happen within 1 to 2 seconds? (0: No, 1: Yes)"

# ---------------------- å»ºç«‹æ¨¡åž‹éª¨æž¶ ----------------------
model_id = "HuggingFaceTB/SmolVLM2-500M-Video-Instruct" if args.smol else "HuggingFaceTB/SmolVLM2-2.2B-Instruct"

if scheme == "adapter":
    # A æ–¹æ¡ˆï¼šéœ€è¦ LoRA çµæ§‹ï¼ˆ4-bit é‡åŒ–ï¼‰ï¼Œå¾…æœƒè¼‰å…¥ adapter Î”W + classifier
    model = SmolVLMWithClassifier(
        model_id=model_id,
        USE_QLORA=True,
        infer=True
    ).to(device).eval()
    # è¼‰å…¥ LoRA Î”W â†’ ç›´æŽ¥ä¸Ÿåˆ° base_modelï¼ˆPeftModelï¼‰
    if adapter_path.exists():
        state_adapter = load_file(str(adapter_path))
        miss_a, unexp_a = model.base_model.load_state_dict(state_adapter, strict=False)
        print(f"[adapter] loaded âœ“  missing={len(miss_a)}  unexpected={len(unexp_a)}")
    else:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° {adapter_path}")
    # è¼‰å…¥åˆ†é¡žé ­
    if clf_path.exists():
        state_clf = load_file(str(clf_path))
        miss_c, unexp_c = model.load_state_dict(state_clf, strict=False)
        print(f"[classifier] loaded âœ“  missing={len(miss_c)}  unexpected={len(unexp_c)}")
    else:
        print("[warn] æ‰¾ä¸åˆ° classifier.safetensorsï¼Œå°‡ä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–çš„åˆ†é¡žé ­ï¼ˆçµæžœå¯èƒ½ä¸æº–ï¼‰")

elif scheme == "merged": 
    # B æ–¹æ¡ˆï¼šä¸éœ€è¦ LoRA çµæ§‹ï¼Œç›´æŽ¥è®€åˆä½µå¾Œå…¨æ¬Šé‡
    model = SmolVLMWithClassifier(
        model_id=model_id,
        USE_QLORA=False,    # ä¸æ’ LoRA
        infer=True
    ).to(device).eval()
    if merged_path.exists():
        state_full = load_file(str(merged_path))
        miss_f, unexp_f = model.load_state_dict(state_full, strict=False)
        print(f"[merged] loaded âœ“  missing={len(miss_f)}  unexpected={len(unexp_f)}")
    else:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° {merged_path}")

else:
    raise RuntimeError(f"Invalid scheme after normalization: {scheme}")


# ---------------------- Processor ------------------------
processor = AutoProcessor.from_pretrained(str(proc_dir))

# ---------------------- å½±ç‰‡æ¸…å–® -------------------------
vid_files = [f for f in os.listdir(video_dir) if f.endswith(".mp4")]
vid_paths = [video_dir / f for f in vid_files]
if not vid_paths:
    raise FileNotFoundError(f"åœ¨ {video_dir} æ‰¾ä¸åˆ° mp4 å½±ç‰‡ã€‚")

# ---------------------- æŽ¨è«–è¿´åœˆ ------------------------
results = []
for path, name in tqdm(list(zip(vid_paths, vid_files)), desc="infer"):
    messages = [{"role": "user",
                 "content": [{"type": "text",  "text": prompt},
                             {"type": "video", "path": str(path)}]}]

    inputs = processor.apply_chat_template(
        messages, tokenize=True, add_generation_prompt=False,
        return_tensors="pt", return_dict=True
    )

    proc_in = {}
    for k, v in inputs.items():
        if not isinstance(v, torch.Tensor):
            continue
        if k == "pixel_values":
            # è‹¥ base_model æœ‰ dtype å°±å°é½Šï¼Œå¦å‰‡æ²¿ç”¨åŽŸ dtypeï¼ˆé¿å…ä¸å¿…è¦ castï¼‰
            target = getattr(model.base_model, "dtype", None)
            proc_in[k] = v.to(device, dtype=target) if target is not None else v.to(device)
        elif k in ("input_ids", "attention_mask"):
            proc_in[k] = v.to(device, dtype=torch.long)
        else:
            proc_in[k] = v.to(device)

    with torch.inference_mode():
        logit = model(**proc_in).squeeze(-1)
        prob  = torch.sigmoid(logit).item()
        pred  = int(prob > 0.5)

    tqdm.write(f"[âœ“] {name} â†’ p={prob:.5f} â‡’ {pred}")
    # file_name = str(path).split("\\")[-1]
    # tqdm.write(f"[âœ“] {file_name} â†’ risk: {pred}, logits: {logit[0]:<9.6f}, probs: {prob[0]:<10.8f}")
    results.append({"file_name": name, "risk": pred})

# ---------------------- å­˜æª” -----------------------------
out_csv.parent.mkdir(parents=True, exist_ok=True)
pd.DataFrame(results).to_csv(out_csv, index=False)
print(f"\nðŸ“„ Results saved to: {out_csv}")
