import os
import torch
import pandas as pd
from safetensors.torch import load_file
from transformers import AutoProcessor
# from smolvlm2_video_FT_clean import SmolVLMWithClassifier, get_latest_checkpoint # original
from smolvlm2_video_FT_strategy3 import SmolVLMWithClassifier, get_latest_checkpoint # strategy3
from tqdm import tqdm
import argparse
import datetime

def parse_args():
    parser = argparse.ArgumentParser(description="Dataset inference script")
    parser.add_argument("--dataset", type=str, required=True, help="Path to the dataset directory")
    parser.add_argument("--epoch", type=str, default=3, required=True, help="fine-tune epoch number")
    parser.add_argument("--model-path", type=str, help="Path to the model directory")
    return parser.parse_args()

args = parse_args()


# 0711
model_path = get_latest_checkpoint(f"C:\\Python_workspace\\TAISC\\code\\smollm-main\\0713_SmolVLM2-500M-Video-Instruct-taisc(strategy3-{args.dataset}-{args.epoch}epoch-complete)") # original
# model_path = "C:\\Python_workspace\\TAISC\\code\\smollm-main\\strategy3 model\\SmolVLM2-500M-Video-Instruct-taisc(latest-cls-strategy3-3epoch)\\checkpoint-36" # strategy3
# model_path = "C:\\Python_workspace\\TAISC\\code\\smollm-main\\SmolVLM2-500M-Video-Instruct-taisc(latest-cls-strategy3-2epoch-complete)-road\\checkpoint-46" # strategy3

model_id = "HuggingFaceTB/SmolVLM2-500M-Video-Instruct"

# æ¸¬è©¦ç”¨å½±ç‰‡èˆ‡æ–‡å­—ï¼ˆè«‹æ ¹æ“šéœ€è¦æ›¿æ›ï¼‰
# video_path = "C:\\Python_workspace\\TAISC\\dataset\\freeway_video\\smolvlm2\\train\\freeway_0000.mp4"
# text_prompt = "Is a vehicle collision likely to happen within 1 to 2 seconds?(0: No, 1: Yes)"
# =======================

# 0711
video_folder = f"C:\\Python_workspace\\TAISC\\dataset\\{args.dataset}_video\\smolvlm2\\test"
# video_folder = f"C:\\Python_workspace\\TAISC\\dataset\\{args.dataset}_val_video\\smolvlm2\\val"

# 0711
# output_csv = "{}_infer_results_{}.csv".format(args.dataset , str(datetime.datetime.now())[11:19].replace(":" , "-"))
output_csv = "0713_strategy3_{}_{}epoch_infer_results_{}.csv".format(args.dataset , args.epoch , str(datetime.datetime.now())[11:19].replace(":" , "-"))
text_prompt = "Is a vehicle collision likely to happen within 1 to 2 seconds?(0: No, 1: Yes)"

# === æ¨¡å‹åˆå§‹åŒ–ä¸¦è®€å–æ¬Šé‡ ===
model = SmolVLMWithClassifier(model_id)
state_dict = load_file(os.path.join(model_path, "model.safetensors"))
model.load_state_dict(state_dict)
model.to("cuda").eval()

# === Processor è¼‰å…¥ ===
processor = AutoProcessor.from_pretrained(model_path)

# æ”¶é›†å½±ç‰‡è·¯å¾‘
video_files = [f for f in os.listdir(video_folder) if f.endswith(".mp4")]
video_paths = [os.path.join(video_folder, f) for f in video_files]

# å„²å­˜æ¨è«–çµæœ
results = []

for video_path, file_name in tqdm(zip(video_paths, video_files)):
    # å»ºç«‹å°è©±è¨Šæ¯
    messages = [{
        "role": "user",
        "content": [
            {"type": "text", "text": text_prompt},
            {"type": "video", "path": video_path}
        ]
    }]
    # è™•ç†è¼¸å…¥
    inputs = processor.apply_chat_template(
        messages,
        add_generation_prompt=False,
        tokenize=True,
        return_tensors="pt",
        return_dict=True
    )
    # ä¾æ¬„ä½æ­£ç¢ºè½‰ dtype
    processed_inputs = {}
    for k, v in inputs.items():
        if not isinstance(v, torch.Tensor):
            continue
        if k == "pixel_values":
            processed_inputs[k] = v.to("cuda", dtype=model.base_model.dtype)
        elif k in ["input_ids", "attention_mask"]:
            processed_inputs[k] = v.to("cuda", dtype=torch.long)
        else:
            processed_inputs[k] = v.to("cuda")
    # æ¨è«–
    with torch.no_grad():
        logits = model(**processed_inputs)
        probs = torch.sigmoid(logits)
        pred = (probs > 0.5).long().item()

    results.append({"file_name": file_name, "risk": pred})
    tqdm.write(f"[âœ“] {file_name} â†’ risk: {pred}, logits: {logits[0]:<9.6f}, probs: {probs[0]:<10.8f}")

        
# å„²å­˜çµæœè‡³ CSV
df = pd.DataFrame(results)
df.to_csv(output_csv, index=False)
print(f"\nğŸ“„ All results saved to: {output_csv}")

# # === æ§‹å»ºå°è©±æ ¼å¼è¼¸å…¥ï¼ˆèˆ‡è¨“ç·´æ™‚ä¸€è‡´ï¼‰ ===
# user_content = [
#     {"type": "text", "text": text_prompt},
#     {"type": "video", "path": video_path}
# ]
# messages = [{"role": "user", "content": user_content}]

# inputs = processor.apply_chat_template(
#     messages,
#     add_generation_prompt=False,
#     tokenize=True,
#     return_tensors="pt",
#     return_dict=True
# )

# # ç§»è‡³ GPU
# # inputs = {k: v.to("cuda") for k, v in inputs.items() if isinstance(v, torch.Tensor)}
# # inputs = {k: v.to("cuda", dtype=model.base_model.dtype) for k, v in inputs.items() if isinstance(v, torch.Tensor)}
# processed_inputs = {}
# for k, v in inputs.items():
#     if not isinstance(v, torch.Tensor):
#         continue
#     if k == "pixel_values":
#         processed_inputs[k] = v.to("cuda", dtype=model.base_model.dtype)
#     elif k in ["input_ids", "attention_mask"]:
#         processed_inputs[k] = v.to("cuda", dtype=torch.long)
#     else:
#         processed_inputs[k] = v.to("cuda")  # é è¨­è½‰ deviceï¼Œä½†ä¿ç•™åŸ dtype
# inputs = processed_inputs

# === æ¨è«– ===
# with torch.no_grad():
#     logits = model(**inputs)
#     probs = torch.sigmoid(logits)
#     preds = (probs > 0.5).long()

# === é¡¯ç¤ºçµæœ ===
# print(f"Logits: {logits.item():.4f}")
# print(f"Probability: {probs.item():.4f}")
# print(f"Predicted Label: {preds.item()}")

# === å„²å­˜çµæœè‡³ CSV ===
# df_output = pd.DataFrame([{
#     "video": os.path.basename(video_path),
#     "logit": logits.item(),
#     "probability": probs.item(),
#     "prediction": preds.item()
# }])
# output_csv_path = "./inference_result.csv"
# df_output.to_csv(output_csv_path, index=False)
# print(f"Inference result saved to: {output_csv_path}")
